{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b658970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# 1. Settings\n",
    "num_samples = 1000\n",
    "feat1_size = 10  # 10 Subjects (Academics)\n",
    "feat2_size = 5   # 5 Behavior Stats\n",
    "num_classes = 10 # Final Grade (0 to 9)\n",
    "\n",
    "# 2. Generate Structured Data (Patterns, not just noise)\n",
    "\n",
    "# --- Branch A: Academics (0.0 to 1.0 representing 0% to 100%) ---\n",
    "# We use a normal distribution so most students are \"average\" (0.5)\n",
    "data_x1_numpy = np.random.normal(loc=0.5, scale=0.15, size=(num_samples, feat1_size))\n",
    "# Clip values to ensure they stay between 0 and 1\n",
    "data_x1_numpy = np.clip(data_x1_numpy, 0, 1).astype(np.float32)\n",
    "\n",
    "# --- Branch B: Behavior (0.0 to 1.0) ---\n",
    "# Similar logic: most students have decent behavior\n",
    "data_x2_numpy = np.random.normal(loc=0.7, scale=0.1, size=(num_samples, feat2_size))\n",
    "data_x2_numpy = np.clip(data_x2_numpy, 0, 1).astype(np.float32)\n",
    "\n",
    "# 3. Create the Target (The \"Secret Formula\")\n",
    "# The Model has to LEARN this formula during training.\n",
    "# Logic: Grade is mostly based on Academics (70% weight) and Behavior (30% weight)\n",
    "avg_academics = np.mean(data_x1_numpy, axis=1) # Average score across 10 subjects\n",
    "avg_behavior = np.mean(data_x2_numpy, axis=1)  # Average behavior score\n",
    "\n",
    "# Calculate a \"Raw Score\" (0.0 to 1.0)\n",
    "raw_score = (0.7 * avg_academics) + (0.3 * avg_behavior)\n",
    "\n",
    "# Add a tiny bit of random noise (because real life isn't perfect)\n",
    "noise = np.random.normal(0, 0.02, size=num_samples)\n",
    "final_score = raw_score + noise\n",
    "\n",
    "# Convert 0.0-1.0 score to a Grade Class (0 to 9)\n",
    "# e.g., 0.95 -> Class 9, 0.1 -> Class 1\n",
    "targets_numpy = (final_score * 10).astype(np.int64)\n",
    "targets_numpy = np.clip(targets_numpy, 0, 9) # Ensure we don't go over 9\n",
    "\n",
    "# 4. Final Conversion to Tensors\n",
    "data_x1 = data_x1_numpy\n",
    "data_x2 = data_x2_numpy\n",
    "data_y = targets_numpy\n",
    "\n",
    "# --- Verification ---\n",
    "print(f\"Student 1 Academics Avg: {avg_academics[0]:.2f}\")\n",
    "print(f\"Student 1 Behavior Avg:  {avg_behavior[0]:.2f}\")\n",
    "print(f\"Student 1 Calculated Grade Class: {data_y[0]}\")\n",
    "print(\"\\nData is ready! There is a discoverable pattern (70% Academics + 30% Behavior).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80427218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "class CustomDatest(Dataset):\n",
    "  def __init__(self,features1,features2,labels):\n",
    "\n",
    "    self.features1=torch.tensor(features1,dtype=torch.float32,device=device)\n",
    "    self.features2=torch.tensor(features2,dtype=torch.float32,device=device)\n",
    "    self.labels=torch.tensor(labels,dtype=torch.long,device=device)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.features1)\n",
    "\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "\n",
    "    return self.features1[index],self.labels[index],self.features2[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e16103",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=CustomDatest(data_x1,data_x2,data_y)\n",
    "data_load_test=DataLoader(training_data,batch_size=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c2e37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, number_of_features1, number_of_features2):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # --- BRANCH 1 (Academics) ---\n",
    "        # FIX: Used nn.Sequential instead of a list []\n",
    "        self.model1 = nn.Sequential(\n",
    "            nn.Linear(number_of_features1, 182),\n",
    "            nn.BatchNorm1d(182),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "\n",
    "            nn.Linear(182, 20),\n",
    "            nn.BatchNorm1d(20),  # FIX: Changed 182 to 20 to match previous layer\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),   # FIX: Removed extra 'nn.'\n",
    "\n",
    "            nn.Linear(20, 4)     # Output is 4 features\n",
    "        )\n",
    "\n",
    "        # --- BRANCH 2 (Behavior) ---\n",
    "        # FIX: Input should likely be 'number_of_features2', not 1\n",
    "        self.model2 = nn.Sequential(\n",
    "            nn.Linear(number_of_features2, 182),\n",
    "            nn.BatchNorm1d(182),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(182, 20)   # Output is 20 features\n",
    "        )\n",
    "\n",
    "        # --- FINAL MERGED LAYER ---\n",
    "        # Input = Output of Model 1 (4) + Output of Model 2 (20) = 24\n",
    "        self.last_layer = nn.Sequential(\n",
    "            nn.Linear(24, 200),\n",
    "            nn.BatchNorm1d(200),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(200, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_features, y_features):\n",
    "        # 1. Process Branch A\n",
    "        output1 = self.model1(x_features)  # Shape: [Batch, 4]\n",
    "\n",
    "        # 2. Process Branch B\n",
    "        output2 = self.model2(y_features)  # Shape: [Batch, 20]\n",
    "\n",
    "        # 3. THE MERGE (Concatenate, don't Add)\n",
    "        # Glue them together side-by-side (dim=1)\n",
    "        # Result Shape: [Batch, 24]\n",
    "        combined_output = torch.cat((output1, output2), dim=1)\n",
    "\n",
    "        # 4. Final Prediction\n",
    "        final_output = self.last_layer(combined_output)\n",
    "\n",
    "        return final_output\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
